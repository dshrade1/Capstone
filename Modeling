load("/project/msca/capstone3/all_tables_appended.RData")

library(lubridate)
library(sqldf)
library("dplyr", lib.loc="/software/R-3.2-el6-x86_64/lib64/R/library")
library("plyr", lib.loc="/software/R-3.2-el6-x86_64/lib64/R/library")
library("rpart", lib.loc="/software/R-3.2-el6-x86_64/lib64/R/library")#Classification Tree
library("party", lib.loc="/home/kjtong/R/x86_64-unknown-linux-gnu-library/3.2")
library("randomForest", lib.loc="/home/kjtong/R/x86_64-unknown-linux-gnu-library/3.2")

########################
#########STEP 1#########
###VARIABLE CREATION####
########################

#Add 'duration' variable
pef3<- patEncFin
pef3$arrival <- ymd_hms(pef3$adm_date_offset)
pef3$departure <- ymd_hms(pef3$disch_date_offset)
pef3$duration <- seconds_to_period(pef3[,10] - pef3[,9])
pef3$los<- day(pef3$duration)#length of stay in days
pef3 <- subset(pef3, !is.na(los)) #remove all NA's because some of the patients are inpatients and some had no hospitalizations, but their date of discharge was still NA 

#Add 'age' to patfin table
join_patfinage <- merge(patfin,pef3,by.x=c("patient_id"),by.y=c("patient_id"), byall.x=TRUE)
join_patfinage$adm_date_offset<-NULL
join_patfinage$disch_date_offset<-NULL
join_patfinage$enc_eio<-NULL
join_patfinage$discharge_dispo<-NULL
join_patfinage$departure<-NULL
join_patfinage$duration<-NULL

#Add sum los + encounter freq
sumlos <- ddply(join_patfinage,.(patient_id),summarise,sumlos=sum(los))  #sum of LOS across encounters
join_patfinage$encounter_id <- 1
encountfreq<-ddply(join_patfinage,.(patient_id),summarise,encountfreq=sum(encounter_id))#find sum of length of stays across encounters
losjoin <- merge(join_patfinage,sumlos,by.x=c("patient_id"),by.y=c("patient_id"), byall.x=TRUE)
encountjoin<- merge(losjoin,encountfreq,by.x=c("patient_id"),by.y=c("patient_id"), byall.x=TRUE)

#Add hospitilizations + total patient costs. 
enc_charges <- merge(charges_all,patEncFin,by.x=c("patient_id","encounter_id"),by.y=c("patient_id","encounter_id"), byall.x=TRUE)
#number of hospitalizations per patient, plus cost
enc_charges$inpatient <- 0
enc_charges$inpatient[which(enc_charges$enc_eio=="E, I,")] <- 1
enc_charges$inpatient[which(enc_charges$enc_eio=="I,")] <- 1
enc_charges$inpatient[which(enc_charges$enc_eio=="I, O,")] <- 1
charges.na <- as.numeric(enc_charges$Charges)
enc_charges$Charges <- as.numeric(enc_charges$Charges)
enc_charges <- enc_charges[-which(is.na(charges.na)),]
patient_util <- ddply(enc_charges,"patient_id",summarise,hospitalizations=sum(inpatient),total_charges=sum(Charges))

patfinutil <- merge(encountjoin, patient_util,by.x=c("patient_id"),by.y=c("patient_id"), byall.x=TRUE)
patfinutil<-patfinutil %>% distinct #remove duplicate rows
length(patfinutil$patient_id)
length(unique(patfinutil$patient_id))
patfinutil<-patfinutil[!duplicated(paste(patfinutil[,1])),] #remove all duplicated patient ID's
patfinutil$encounter_id<-NULL
patfinutil$los<-NULL



########################
#########STEP 2#########
#########CLUSTER########
########################

#cluster charges
#NON-TRANSFORMED
trainmatrix<- data.matrix(patfinutil)
km.charges <- kmeans(data.matrix(patfinutil[,13]), 6, nstart=50)
plot(data.matrix(trainmatrix[,13]), col = (km.charges$cluster+1), main = "Non-Transformed k=6", pch=20, cex=1)
km.charges$centers
#NOTE: cluster #s change after each run, so double check!
#Bind cluster categories w/ 'charges' table
finalData.untrans <- cbind(patfinutil, chargesClustered = km.charges$cluster)                                              

#TRANSFORMED
#cluster charges on Transformed data, K=6
#transform train for linear models
df <- patfinutil
y=log(df$total_charges)#transform y to normal distribution
df$total_charges2 <- replace(y,y=="-Inf",0)#remove -inf

#W/OUT 0 - lm models
lm.data.nozero <- subset(df, total_charges > 0) #remove 0's 
trainmatrix<-data.matrix(lm.data.nozero)
km.charges <- kmeans(data.matrix(lm.data.nozero[,13]), 6, nstart=50)
plot(data.matrix(trainmatrix[,13]), col = (km.charges$cluster+1), main = "Transformed W/out 0, k=6", pch=20, cex=1)
km.charges$centers
#NOTE: cluster #s change after each run, so double check!
#Bind cluster categories w/ 'charges' table
finalData.trans.without0 <- cbind(lm.data.nozero, chargesClustered = km.charges$cluster)                                              

#W/ 0 - non lm models
lm.data.withzero <- df 
trainmatrix<-data.matrix(lm.data.withzero)
km.charges <- kmeans(data.matrix(lm.data.withzero[,13]), 6, nstart=50)
plot(data.matrix(trainmatrix[,13]), col = (km.charges$cluster+1), main = "Transformed W/ 0, k=6", pch=20, cex=1)
km.charges$centers
#NOTE: cluster #s change after each run, so double check!
#Bind cluster categories w/ 'charges' table
finalData.trans.with0 <- cbind(lm.data.withzero, chargesClustered = km.charges$cluster) 

############
#FINAL DATA:
# data <- finalData.untrans
data <- finalData.trans.without0    #lm
# data <- finalData.trans.with0       #non-lm
############

#Create Charge Cluster data
c1 <- data[data$chargesClustered == 1,]
c2 <- data[data$chargesClustered == 2,]
c3 <- data[data$chargesClustered == 3,]
c4 <- data[data$chargesClustered == 4,]
c5 <- data[data$chargesClustered == 5,]
c6 <- data[data$chargesClustered == 6,]

#Summary of clusters
summary(c1)[,3];summary(c2)[,3];summary(c3)[,3];summary(c4)[,3];summary(c5)[,3];summary(c6)[,3]
nrow(c1); nrow(c2);nrow(c3);nrow(c4);nrow(c5)
#mean charge by race by cluster
ddply(c6, .(sex), summarise, mean_charge=mean(total_charges))


########################
#########STEP 3#########
######TEST / TRAIN######
########################

#Train = All '12 + Q1,Q2 '13 + 50% of random('13Q3 - '14Q2)
#Test = All '15 + Q3,Q4 '14 + 50% of random('12Q3 - '13Q2)
# 50% split
split1 <- data[ which(data$arrival > "2013-07-01" & data$arrival <= "2014-06-30"),]
ssize <- floor(0.5*nrow(split1))
train_ind <- sample(seq_len(nrow(split1)), size= ssize)
hist(data$arrival, breaks = 100)  #Distribution of time

train1 <- data[data$arrival <= "2013-01-01",]
train2 <- data[ which(data$arrival > "2013-01-01" & data$arrival <= "2013-07-01"),]
train3 <- split1[train_ind,]
train <- rbind(train1, train2, train3)
train$where <- 1

#Test
test1 <- data[data$arrival > "2015-01-01",]
test2 <- data[ which(data$arrival > "2014-06-30" & data$arrival <= "2015-01-01"),]
test3 <- split1[-train_ind,]
test <-  rbind(test1, test2, test3)
test$where <- 0

# #Test/Train based on mean arrival
# train.mean <- data[data$arrival >= mean(data$arrival),]
# test.mean <- data[data$arrival < mean(data$arrival),]
# 
# #Test/Train based on median arrival
# train.median <- data[data$arrival >= median(data$arrival),]
# test.median <- data[data$arrival < median(data$arrival),]


########################
#########STEP 4#########
######LINEAR REG########
########################

#Full population
hist(train$total_charges)

#lm Hospitalizations
fulllmhosp<-lm(total_charges~hospitalizations, data=train)
summary(fulllmhosp)
# plot(fulllmhosp)
fulllmhosp.MSE <- mean((fulllmhosp$fitted.values - train$total_charges)^2)

#Sum LOS
fulllmlos<-lm(total_charges~sumlos, data=train)
summary(fulllmlos)
# plot(fulllmlos)
fulllmlos.MSE <- mean((fulllmlos$fitted.values - train$total_charges)^2)

#EncountFreq
fulllmencount<-lm(total_charges~encountfreq, data=train)
summary(fulllmencount)
# plot(fulllmencount)
fulllmencount.MSE <- mean((fulllmencount$fitted.values - train$total_charges)^2)

#Total
fulllmhosplosencount<-lm(total_charges~hospitalizations+sumlos+encountfreq, data=train)
summary(fulllmhosplosencount)
anova(fulllmhosplosencount)
# plot(fulllmhosplosencount)
fulllmhosplosencount.MSE <- mean((fulllmhosplosencount$fitted.values - train$total_charges)^2)

predictfull<-predict(fulllmhosplosencount,newdata=test)
summary(predictfull)
fulllmhosplosencounttest.MSE <- mean((predictfull - test$total_charges)^2)
plot(predictfull)
hist(predictfull)

#The transformed model with all 3 predictors performs best, hospitalizations is best predictor
#Regressions for each cluster
c1lm<-lm(total_charges~hospitalizations+sumlos+encountfreq, data=c1)
summary(c1lm)
c1.MSE <- mean((c1lm$fitted.values - c1$total_charges)^2)

c2lm<-lm(total_charges~hospitalizations+sumlos+encountfreq, data=c2)
summary(c2lm)
c2.MSE <- mean((c2lm$fitted.values - c2$total_charges)^2)

c3lm<-lm(total_charges~hospitalizations+sumlos+encountfreq, data=c3)
summary(c3lm)
c3.MSE <- mean((c3lm$fitted.values - c3$total_charges)^2)

c4lm<-lm(total_charges~hospitalizations+sumlos+encountfreq, data=c4)
summary(c4lm)
c4.MSE <- mean((c4lm$fitted.values - c4$total_charges)^2)

c5lm<-lm(total_charges~hospitalizations+sumlos+encountfreq, data=c5)
summary(c5lm)
c5.MSE <- mean((c5lm$fitted.values - c5$total_charges)^2)

c6lm<-lm(total_charges~hospitalizations+sumlos+encountfreq, data=c6)
summary(c6lm)
c6.MSE <- mean((c6lm$fitted.values - c6$total_charges)^2)

##################
##################
###COMPARATIVE STATS######
#MSE
fulllmhosp.MSE
fulllmlos.MSE
fulllmencount.MSE
fulllmhosplosencount.MSE
c1.MSE;c2.MSE;c3.MSE;c4.MSE;c5.MSE;c6.MSE

AIC(fulllmhosp)
AIC(fulllmlos)
AIC(fulllmencount)
AIC(fulllmhosplosencount)
AIC(c5lm);AIC(c1lm);AIC(c2lm);AIC(c3lm);AIC(c4lm)




########################
#########STEP 5#########
######DECISION TREE#####
########################

#Decision Tree

#Cluster Numerical Columns
#train$age_at_enc: 109 unique to

#train$sumlos: 137 unique to 

#train$encountfreq: 147 unique to 

#Data for model
df <- rbind(train, test)

a <- model.matrix(race ~ as.factor(chargesClustered), df)
a <- as.data.frame(a)
colnames(a) <- c("intercept", "c2", "c3","c4","c5","c6")
a <- a[,c(2:6)]
df2 <- cbind(df,a)

train2 <- 1:nrow(train)
df.test <- df2[-train2,]
c2 <- df2$c2
c2.test <-  c2[-train2]

###DTree#########
t.charges <- rpart(c2 ~ sex + race + marital_status + enc_fin_class + factor(sumlos) + encountfreq + hospitalizations, 
                   data=df2,
                   subset = train2,
                   method = "class",                      #classification used
                   parms = list(split = "information"),   #entropy/deviance used
                   cp = 0)                                #no size penalty
summary(t.charges)  #show splits
t.pred <- predict(t.charges, df.test, type = "class")
table(t.pred, c2.test)
misclassificationRate <- (1433+878) / 15970; misclassificationRate
correct = 1-misclassificationRate; correct
#I get correct predictions 85.5% of the time

#Plot   
plot(t.charges, uniform = TRUE, compress = TRUE, margin=0.0001, main = "km 6 DT")
text(t.charges, use.n=TRUE,all=TRUE, cex = 0.8)                              
#show results
result <- printcp(t.charges)
plotcp(t.charges) #cross-validation results
#Tree with lowest xerror with 0.7686 is a tree with nsplit = 48 length

newwindow()
colors <- apply(matrix())

#Consider pruning the tree to get improved results
cv.charges <- cv.tree(t.charges, FUN=prune.misclass)










#party package
ct <- ctree(fml, data=ttrain)
# plot(ct, main = "Conditional Inference Tree")
table(predict(ct, newdata = test, type = "prob"))

#Estimate test error #CAN"T WORK
# tree.pred <- predict(t.charges, test[,c(2,3,5,7,8,10,11,12)], type = "class")    #ERROR cuz won't calculate
# table(tree.pred, test, type = "class")


########################
#########STEP 7#########
######RANDOM FOREST#####
########################
rf.fit <- randomForest(fml, data = ttrain2,
                       mtry = 10,
                       ntree= 50,
                       importance = TRUE,
                       test = test$cl)
