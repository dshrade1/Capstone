#Local Computer
# setwd("~/Desktop/GDrive/Courses/Capstone/FinalPaper/adminfo")
# load("patient_matrix.RData")
# load("patient_matrix2.RData")
# load("patient_matrixrevise.RData")
# load("test_ids.RData")
# load("train_ids.RData")
# load("patient_matrix_centered.RData")
# library("lubridate")
library("sqldf");library("dplyr");library("ggplot2");library("plyr");library("rpart");library("randomForest");library("caret");library("mlbench")


#RCC
load("/project/msca/capstone3/patient_matrix_centered.RData")
# load("/project/msca/capstone3/train_ids.RData")
# load("/project/msca/capstone3/test_ids.RData")
#library(lubridate)
# library("dplyr", lib.loc="/software/R-3.2-el6-x86_64/lib64/R/library")
# library("plyr", lib.loc="/software/R-3.2-el6-x86_64/lib64/R/library")
# library("rpart", lib.loc="/software/R-3.2-el6-x86_64/lib64/R/library")#Classification Tree
# library("randomForest", lib.loc="/home/kjtong/R/x86_64-unknown-linux-gnu-library/3.2")
# library("ggplot2", lib.loc="/software/R-3.2-el6-x86_64/lib64/R/library")

#Variable Creation in Patient_level_Matrix.R
#Train/Test Split in TrainTestSplits_Grace.R


######################################
##########STEP 3######################
##POST TRAIN/TEST VARIABLE CREATION###
######################################


#TRANSFORMED
#transform train for linear models
########
data <- patient_matrix  #or pm5
########

data$y2_charges <- data$y2_charges + 1 
data$y1_charges <- data$y1_charges + 1
data$y1_charges_log <- log(data$y1_charges)#transform charges to normal distribution 
data$y2_charges_log <- log(data$y2_charges)#transform charges to normal distribution 
# 
# #Train
# train <- data[data$patient_id %in% train_ids,]
# #Test
# test <- data[data$patient_id %in% test_ids,]


########################
#########STEP 4#########
#########CLUSTER########
########################
#Cluster on year1 & year2 Charges
set.seed(10)
dfMatrix<-data.matrix(data)
km.y1charges.log <- kmeans(data.matrix(dfMatrix[,15]), centers = 4, nstart=2)
km.y2charges.log <- kmeans(data.matrix(dfMatrix[,16]), centers = 4, nstart=2)

km.y1charges <- kmeans(data.matrix(dfMatrix[,7]), centers = 10, nstart=2)
km.y2charges <- kmeans(data.matrix(dfMatrix[,8]), centers = 10, nstart=2)
# plot(data.matrix(trainMatrix[,17]), col = (km.charges.log$cluster+1), main = "Clusters Logged", pch=20, cex=1)
# plot(data.matrix(trainMatrix[,9]), col = (km.charges$cluster+1), main = "Clusters NoLogged", pch=20, cex=1)

length(km.y1charges.log$cluster);length(km.y2charges.log$cluster)
length(km.y1charges$cluster);length(km.y2charges$cluster) 
#NOTE: cluster #s change after each run, so double check!
#Bind cluster categories w/ 'charges' table
data2 <- cbind(data, y1chargesClusteredLog = km.y1charges.log$cluster)
data3 <- cbind(data2, y2chargesClusteredLog = km.y2charges.log$cluster)
data4 <- cbind(data3, y1chargesClustered = km.y1charges$cluster)
data5 <- cbind(data4, y2chargesClustered = km.y2charges$cluster)

############
#FINAL DATA:
data <- data5
# save(data, file = "/home/jberthet/finalData2.RData")
load("/home/jberthet/finalData2.RData")


# load("~/Desktop/GDrive/Courses/Capstone/FinalPaper/adminfo/finalData2.RData")



#Create Charge Cluster Log data
# c1 <- data[data$chargesClusteredLog == 1,]
# c2 <- data[data$chargesClusteredLog == 2,]
# c3 <- data[data$chargesClusteredLog == 3,]
# c4 <- data[data$chargesClusteredLog == 4,]
# c5 <- data[data$chargesClusteredLog == 5,]
# c6 <- data[data$chargesClusteredLog == 6,]

#Summary of charges by clusters
# summary(c1)[,24]
# summary(c2)[,24]
# summary(c3)[,24]
# summary(c4)[,24]
# summary(c5)[,24]
# summary(c6)[,24]
# nrow(c1); nrow(c2);nrow(c3);nrow(c4);nrow(c5)
# #mean charge by race by cluster
# ddply(c6, .(sex), summarise, mean_charge=mean(y2_charges_))


########################
#########STEP 5#########
######LINEAR REG########
########################

#Full population
# hist(train$total_charges2)
# 
# #lm Hospitalizations
# fulllmhosp<-lm(total_charges2 ~ hospitalizations, data=train)
# summary(fulllmhosp)
# # plot(fulllmhosp)
# fulllmhosp.MSE <- mean((fulllmhosp$fitted.values - train$total_charges2)^2)
# 
# #Sum LOS
# fulllmlos<-lm(total_charges2~sumlos, data=train)
# summary(fulllmlos)
# # plot(fulllmlos)
# fulllmlos.MSE <- mean((fulllmlos$fitted.values - train$total_charges2)^2)
# 
# #EncountFreq
# fulllmencount<-lm(total_charges2~encountfreq, data=train)
# summary(fulllmencount)
# # plot(fulllmencount)
# fulllmencount.MSE <- mean((fulllmencount$fitted.values - train$total_charges2)^2)
# 
# #Total
# fulllmhosplosencount<-lm(total_charges2 ~ hospitalizations+sumlos+encountfreq, data=train)
# summary(fulllmhosplosencount)
# anova(fulllmhosplosencount)
# # plot(fulllmhosplosencount)
# fulllmhosplosencount.MSE <- mean((fulllmhosplosencount$fitted.values - train$total_charges2)^2)
# 
# predictfull<-predict(fulllmhosplosencount,newdata=test)
# summary(predictfull)
# fulllmhosplosencounttest.MSE <- mean((predictfull - test$total_charges2)^2)
# plot(predictfull)
# hist(predictfull)
# 
# #Regressions for each cluster
# c1lm<-lm(total_charges2~hospitalizations+sumlos+encountfreq, data=c1)
# summary(c1lm)
# c1.MSE <- mean((c1lm$fitted.values - c1$total_charges2)^2)
# 
# c2lm<-lm(total_charges2~hospitalizations+sumlos+encountfreq, data=c2)
# summary(c2lm)
# c2.MSE <- mean((c2lm$fitted.values - c2$total_charges2)^2)
# 
# c3lm<-lm(total_charges2~hospitalizations+sumlos+encountfreq, data=c3)
# summary(c3lm)
# c3.MSE <- mean((c3lm$fitted.values - c3$total_charges2)^2)
# 
# c4lm<-lm(total_charges2~hospitalizations+sumlos+encountfreq, data=c4)
# summary(c4lm)
# c4.MSE <- mean((c4lm$fitted.values - c4$total_charges2)^2)
# 
# c5lm<-lm(total_charges2~hospitalizations+sumlos+encountfreq, data=c5)
# summary(c5lm)
# c5.MSE <- mean((c5lm$fitted.values - c5$total_charges2)^2)
# 
# c6lm<-lm(total_charges2~hospitalizations+sumlos+encountfreq, data=c6)
# summary(c6lm)
# c6.MSE <- mean((c6lm$fitted.values - c6$total_charges2)^2)
# 
# 
# 
# ###COMPARATIVE STATS
# #MSE
# fulllmhosp.MSE
# fulllmlos.MSE
# fulllmencount.MSE
# fulllmhosplosencount.MSE
# c1.MSE;c2.MSE;c3.MSE;c4.MSE;c5.MSE;c6.MSE
# 
# #AIC
# AIC(fulllmhosp)
# AIC(fulllmlos)
# AIC(fulllmencount)
# AIC(fulllmhosplosencount)
# AIC(c1lm);AIC(c2lm);AIC(c3lm);AIC(c4lm);AIC(c5lm);AIC(c6lm)

########################
#########STEP 6#########
######DECISION TREE#####
########################


#Create df for Decision Tree
a <- model.matrix(race ~ as.factor(chargesClustered), df)
a <- as.data.frame(a)
colnames(a) <- c("intercept", "c2", "c3","c4","c5","c6")
a <- a[,c(2:6)]
df2 <- cbind(df,a)
df2$c1 <- ifelse(df2$chargesClustered == 1,1,0)

#Cluster Numerical Columns
#train$age_at_enc: 109 unique to 20
trainmatrix<- data.matrix(df2)
km.age <- kmeans(data.matrix(df2$age_at_enc), 20, nstart=50)
# plot(data.matrix(trainmatrix[,7]), col = (km.charges$cluster+1), main = "Non-Transformed k=6", pch=20, cex=1)
#NOTE: cluster #s change after each run, so double check!
#Bind cluster categories w/ 'df2' table
df2 <- cbind(df2, ageClustered = km.age$cluster)     

#train$sumlos: 137 unique to 20
trainmatrix<- data.matrix(df2)
km.sumlos <- kmeans(data.matrix(df2$sumlos), 20, nstart=50)
# plot(data.matrix(trainmatrix[,10]), col = (km.charges$cluster+1), main = "Non-Transformed k=6", pch=20, cex=1)
#Bind cluster categories w/ 'df2' table
df2 <- cbind(df2, sumlosClustered = km.sumlos$cluster)     

#train$encountfreq: 147 unique to 20
trainmatrix<- data.matrix(df2)
km.encountfreq <- kmeans(data.matrix(df2$encountfreq), 20, nstart=50)
# plot(data.matrix(trainmatrix[,11]), col = (km.charges$cluster+1), main = "Non-Transformed k=6", pch=20, cex=1)
#Bind cluster categories w/ 'df2' table
df2 <- cbind(df2, encountfreqClustered = km.encountfreq$cluster)

#####CHOOSE CLUSTER TEST######
train2 <- 1:nrow(train)
df.test <- df2[-train2,]
c1 <- df2$c1;c2 <- df2$c2;c3 <- df2$c3;c4 <- df2$c4;c5 <- df2$c5;c6 <- df2$c6;
######################
#CHOOSE....WISELY...
# cluster <- c1 ; cluster.test <-  c1[-train2]
# cluster <- c2 ; cluster.test <-  c2[-train2]
# cluster <- c3 ; cluster.test <-  c3[-train2]
# cluster <- c4 ; cluster.test <-  c4[-train2]
cluster <- c5 ; cluster.test <-  c5[-train2]
# cluster <- c6 ; cluster.test <-  c6[-train2]
#################

#Mixed
varsm <- sumlos + encountfreq + hospitalizations + num_ER_visits + mode_discharge_dispo + y1_charges + sex + race + marital_status + dod_off + age_y2 + y1_charges_log + y1chargesClusteredLog + y1chargesClustered

#All Factor  
varsf <- factor(sumlos) + factor(encountfreq) + factor(hospitalizations) + factor(num_ER_visits) + mode_discharge_dispo + factor(y1_charges) + sex + race + marital_status + dod_off + factor(age_y2) + factor(y1_charges_log) + factor(y1chargesClusteredLog) + factor(y1chargesClustered)




######DTree#########
#Regression Tree(method="anova")
#Classification Tree(method="class")
tree.charges <- rpart(y2chargesClustered ~ factor(sumlos) + factor(encountfreq) + factor(hospitalizations) + factor(num_ER_visits) + mode_discharge_dispo + factor(y1_charges) + sex + race + marital_status + dod_off + factor(age_y2) + factor(y1_charges_log) + factor(y1chargesClusteredLog) + factor(y1chargesClustered), 
                      data= data
                      subset = train_ids,
                      method = "class",                      #classification used
                      parms = list(split = "information"),   #entropy/deviance used
                      cp = 0)        #no size penalty

tree.charges <- rpart(y2_charges ~ sex + race,
                      data= pm5,
                      subset = train_ids,
                      method = "class",                      #classification used
                      parms = list(split = "information"),   #entropy/deviance used
                      cp = 0)  
# summary(t.charges)  #show splits

#Predict on Test set
t.pred <- predict(t.charges, df.test, type = "class")
table(t.pred, cluster.test)
misclassificationRate <- (1045+2915) / 15970; misclassificationRate
correct = 1-misclassificationRate; correct

#Plot                                
#show results
result <- printcp(t.charges)
min(result[,4])   #get CP from lowest xerror
plotcp(t.charges, col = 2, upper = "size", cex=.1) #cross-validation results
summary(t.charges)
plot(t.charges, uniform=TRUE, main = "Year 2 Charges Prediction")
text(t.charges, use.n=TRUE, all=TRUE, cex=0.8)
#Alternative postcript plot
# post(t.charges, file = "/project/msca/capstone3/plots/tree.ps", title = "Classification Tree)
#Tree with lowest xerror with 0.7686 is a tree with nsplit = 48 length
#However, 2nd lowest xerror has 0.76953 is nsplit=30. Let's try that! (cp = 1.365498e-03 )

#Prune
t.charges.prune <- prune(t.charges, cp =
                           t.charges$cptable[which.min(t.charges$cptable[,"xerror"]),"CP"])

#Plot Prunned Tree
plot(t.charges.prune, uniform=TRUE)
text(t.charges.prune, use.n=TRUE, all=TRUE, cex=0.8)

#Predict on Test set
t.pred <- predict(df2.prune, df.test, type = "class")
table(t.pred, cluster.test)
misclassificationRate <- (881+2980) / 15970; misclassificationRate
correct = 1-misclassificationRate; correct

plot(df2.prune, uniform = TRUE, compress = TRUE, margin=0.0001, main = "km 6 DT")
text(df2.prune, use.n=TRUE,all=TRUE, fancy = TRUE, cex = 0.8)      



########################
#########STEP 7#########
######RANDOM FOREST#####
########################

#Conduct Bagging, which is rf with m = p
inTraining = createDataPartition(data$y2chargesClustered, p = .75, list = F)
training = data[inTraining,]
testing = data[-inTraining,]

set.seed(10)
fml <- y2chargesClustered ~ factor(sumlos) + factor(encountfreq) + factor(hospitalizations) + factor(num_ER_visits) + mode_discharge_dispo + factor(y1_charges) + sex + race + marital_status + dod_off + factor(age_y2) + factor(y1_charges_log) + factor(y1chargesClusteredLog) + factor(y1chargesClustered)

bag.df2 <- randomForest(fml, 
                        data=data,
                        subset = training,
                        mtry = 3,        #Consider all predictors
                        ntree= 50,
                        importance = TRUE)
bag.df2

#Boosting
# yhat.bag <- predict(bag.df2, newdata = df.test, type = "class")
# df2.test <- df2[-train]
# 
# par(mfrow=c(1,1))
# plot(yhat.bag, cluster.test)
# abline(0,1)
# mean((yhat.bag - cluster.test)^2)

# importance(bag.df2)
varImpPlot(bag.df2, main = "c6")

#CV RF for variable selection
charge_rfcv <- rfcv(train[,c(3,13,15,17:23)], train[,24], cv.folds=5)
with(charge_rfcv, plot(n.var, error.cv, log="x", type = "o", lwd=2))


#################
#Random Forest
#Adam's Code w/ Kappa Metric
inTraining = createDataPartition(data$y2chargesClustered, p = .75, list = F)
training = data[inTraining,]
testing = data[-inTraining,]

# means you do 12-fold CV and you do that 5 times.
fitControl = trainControl(method = 'repeatedcv', number = 12, repeats = 5)

gbmFit1 = train(y2chargesClustered ~ 
                  factor(sumlos) + factor(encountfreq) + factor(hospitalizations) + factor(num_ER_visits) + mode_discharge_dispo + factor(y1_charges) + sex + race + marital_status + dod_off + factor(age_y2) + factor(y1_charges_log) + factor(y1chargesClusteredLog) + factor(y1chargesClustered),
                data=training, trControl = fitControl, verbose = F)
gbmFit1
#################



#SVM
#Divide Data into train/test
inTrain = createDataPartition(data$y2chargesClustered, p = .75, list = F)
trainData <- data[inTrain,]
testData  <- data[-inTrain,]
#Select y-variable as vector
train_y <- data$y2chargesClustered[inTrain]
test_y  <- data$y2chargesClustered[-inTrain]
prop.table(table(train_y))
prop.table(table(test_y))

#Remove variables w/ above 0.9 correlation
# Linear models, neural networks and other models can have poor performance in these situations or may generate unstable solutions. Other models, such as classification or regression trees, might be resistant to highly correlated predictors, but multicollinearity may negatively affect interpretability of the model. For example, a classification tree may have good performance with highly correlated predictors, but the determination of which predictors are in the model is random.
ncol(trainData)
dataCorr <- cor(trainData[,c(2,3,4,5,7,14,15)])
highCorr <- findCorrelation(dataCorr, 0.90)
trainDescr <- trainData[, -highCorr]
testDescr  <-  testData[, -highCorr]
ncol(trainData)

# Some models, such as partial least squares, neural networks and support vector machines, need the predictor variables to be centered and/or scaled.
# The preProcess function can be used to determine values for predictor transformations us- ing the training set and can be applied to the test set or future samples. The function has an argument, method, that can have possible values of "center", "scale", "pca" and "spatialSign". The first two options provide simple location and scale transformations of each predictor (and are the default values of method). The predict method for this class is then used to apply the processing to new samples
xTrans <- preProcess(trainData[,c(2,3,4,5,7,14,15)])   #Select only numeric variables
trainData <- predict(xTrans, trainData[,c(2,3,4,5,7,14,15)])
testData  <- predict(xTrans,  testData[,c(2,3,4,5,7,14,15)])

# We can tune and build the SVM model using the code below.
bootControl <- trainControl(number = 200)
set.seed(2)
svmFit <- train(trainData, train_y,
                method = "svmRadial", tuneLength = 5,
                trControl = bootControl, scaled = FALSE)
# Model 1: sigma=0.0004329517, C=1e-01 #Models 2-5 also listed
svmFit

svmFit$finalModel




#tune over the number of trees (i.e., boosting iterations), the complexity of the tree (indexed by interaction.depth) and the learning #rate (also known as shrinkage). As an example, a user could specify a grid of values to tune over using a data frame where the rows #correspond to tuning parameter combinations and the columns are the names of the tuning variables (preceded by a dot). For our #data, we will generate a grid of 50 combinations and use the tuneGrid argument to the train function to use these values.
#we generated 200 bootstrap replications for each of the 50 candidate models, computed performance and selected the model with the largest accuracy.

gbmGrid <- expand.grid(.interaction.depth = (1:5) * 2,
                          .n.trees = (1:10)*25, 
                          .shrinkage = .1)
set.seed(2)
gbmFit <- train(trainData, train_y,
                   method = "gbm", trControl = bootControl, verbose = FALSE,
                   bag.fraction = 0.5, tuneGrid = gbmGrid)



# (a) A plot of the classification accuracy versus the tuning factors 
(using plot(gbmFit))
# (b) Similarly, a plot of the Kappa statistic profiles 
(plot(gbmFit, metric = "Kappa"))
# (c) A level plot of the accuracy values 
(plot(gbmFit, plotType = "level"))
# (d) Density plots of the 200 bootstrap estimates of accuracy and Kappa for the final model 
(resampleHist(gbmFit))

####PREDICTION OF NEW SAMPLES####
predict(svmFit$finalModel, newdata = testData)[1:5]
models <- list(svm = svmFit, gbm = gbmFit)
testPred <- predict(models, newdata = testData)
lapply(testPred, function(x) x[1:5])

predValues <- extractPrediction(models, testX = testData, testY = test_y)
testValues <- subset(predValues, dataType == "Test")
head(testValues)
table(testValues$model)
nrow(testDescr)


probValues <- extractProb(models, testX = testData, testY = test_y)
testProbs <- subset(probValues, dataType == "Test")
str(testProbs)

####CHARACTERIZATING PERFORMANCE####
svmPred <- subset(testValues, model == "svmRadial")
confusionMatrix(svmPred$pred, svmPred$obs)

svmProb <- subset(testProbs, model == "svmRadial")
svmROC <- roc(svmProb$data$y2chargesClustered, svmProb$obs)
str(svmROC)

####PREDICTOR IMPORTANCE####
gbmImp <- varImp(gbmFit, scale = FALSE)
gbmImp
plot(varImp(gbmFit), top = 20))

#NN
